---
title: "ITS2 amplicon cleanup in Cloquet DNA optimization trial"
output:
  html_notebook
---

## Load packages and data
```{r}
sapply(c("phyloseq", "ggplot2", "ggClusterNet", "dplyr", "microbiome", "ggpubr",
         "decontam", "rstatix"),
       require, character.only = TRUE)

ps.its = readRDS("../05_tophyloseq/results/ps.its.rds")
sample_data(ps.its)$Protocol <-factor(sample_data(ps.its)$Protocol, level = c("QIAGEN",
                                                                              "CTAB"))
```

## Statistic of raw reads befpre processing
```{r}
depth_track <- data.frame(sample_data(ps.its)) %>%
  mutate(raw = sample_sums(ps.its)) %>%
  mutate(SampleID = row.names(.))

depth_track %>%
  group_by(Sample_or_Control) %>%
  dplyr::summarise(range(raw), mean(raw), sd(raw))

depth_track %>%
  # remove decayed samples in time 0 (pine log 06, pine log 07)
  #subset(! row.names(depth_track) %in% c("C36","Q36", "C37", "Q37")) %>% # 36, 37 has blue dye in time 0 sample
  filter(Sample_or_Control == "Sample") %>%
  mutate(status = ifelse(Year_since_decay_start %in% c(0), "non_decayed", "decayed")) %>%
  group_by(Tree_host, status) %>%
  dplyr::summarise(mean(raw), sd(raw))

depth_track %>%
  group_by(Tree_host, Protocol, Year_since_decay_start) %>%
  dplyr::summarise(mean(raw), sd(raw))
```


## Taxonomic based filtering
The non-fungal taxa need to be removed.
```{r}
unique(tax_table(ps.its)[, "Kingdom"])
length(unique(tax_table(ps.its)[, "Kingdom"])) # 11

## Pick up the NA kingdom (111)
ps.k.na = subset_taxa(ps.its, is.na(Kingdom)) # 360
# Recover DNA sequence and save in fasta format
rep.seq.k.na <- refseq(ps.k.na)
Biostrings::writeXStringSet(rep.seq.k.na,  file = "results/rep_seqs_kingdom_na.fasta", format = "fasta")
## Blast the NA sequence and I found some of them were fungi and the question is how to filter them based on a ## criterion and add them to the taxa table?
# I will remove those NA sequences as They're not so much

# Remove non-fungal taxa
ps.fungi = subset_taxa(ps.its, Kingdom == "k__Fungi") # there was 2456 fungal taxa
saveRDS(ps.fungi, "results/ps.fungi.rds")

ps.nonfungi = subset_taxa(ps.its, ! Kingdom == "k__Fungi"| is.na(Kingdom)) # there was 2399 nonfungal taxa
saveRDS(ps.nonfungi, "results/ps.nonfungi.rds") # there was 4855-2456=2399 non-fungal taxa

## Pick up the NA phylum (51)
ps.na = subset_taxa(ps.fungi, is.na(Phylum)) 
# Recover DNA sequence and save in fasta format
rep.seq.na <- refseq(ps.na)
Biostrings::writeXStringSet(rep.seq.na,  file = "results/rep_seqs_na_new.fasta", format = "fasta")

## Blast the NA sequence to pick put the host sequence
# The NA sequence are fungal sequence

# Remove unknown phylum
#ps.known = subset_taxa(ps.fungi, !is.na(Phylum)) # 2456-51= 2405 was removed.
#saveRDS(ps.known, "results/rm_un/ps.known.rds")

# Make a data frame with a column for the read counts of each sample
depth_track1 <- data.frame(sample_data(ps.fungi)) %>%
  mutate(nonfungal_filtered = sample_sums(ps.fungi)) %>%
  right_join(depth_track)

# Histogram of sample read counts
p <- ggplot(depth_track1, aes(x=nonfungal_filtered, fill=Protocol))+
  geom_histogram()+
  scale_x_log10()+
  facet_grid(Protocol~Year_since_decay_start)+
  scale_color_manual(values =  c("#F8766D", "#00BA38")) +
  scale_fill_manual(values =  c("#F8766D", "#00BA38")) +
  ggtitle("Distribution of sequencing depth")+
  labs(x = "Total reads")+
  theme(axis.text.x=element_text(angle=45,vjust=1, hjust=1)) +
  theme_bw(7)+
  theme(legend.key.size = unit(0.2, "cm"),
                    legend.title = element_blank()) 
p
ggsave("results/pictures/newdatabase/Distribution_of_sample_sequencing_depth.pdf", p)

# Statistic of reads after removing non-fungal reads
depth_track1 %>%
  group_by(Tree_host, Protocol, Year_since_decay_start) %>%
  dplyr::summarise(mean(nonfungal_filtered), sd(nonfungal_filtered))

depth_track1 %>%
  # remove decayed samples in time 0 (pine log 06, pine log 07)
  #subset(! row.names(depth_track) %in% c("C36","Q36", "C37", "Q37")) %>% # 36, 37 has blue dye in time 0 sample
  filter(Sample_or_Control == "Sample") %>%
  mutate(status = ifelse(Year_since_decay_start %in% c(0), "non_decayed", "decayed")) %>%
  group_by(Tree_host, status) %>%
  dplyr::summarise(mean(nonfungal_filtered), sd(nonfungal_filtered))
```

```{r}
# Statistical summary of ASV classified as non fungi (kingdom = "k__Fungi" )
length(get_taxa_unique(ps.its,taxonomic.rank="Kingdom"))

Kingdoms <- ps.its %>%
  aggregate_taxa("Kingdom") %>% 
  transform_sample_counts(function(x) {x/sum(x)}) %>% 
  psmelt() %>%
  arrange(Kingdom)
King_stat <- Kingdoms %>%
  dplyr::group_by(Tree_host,  Year_since_decay_start, Kingdom) %>%
  dplyr::summarise(mean=mean(Abundance)*100, sd=sd(Abundance)) %>%
  arrange(dplyr::desc(mean)) %>%
  as.data.frame()
write.csv(King_stat, "results/kingdom_stats.csv")

paste( "The reads of ", King_stat[6,3], " is ",round(King_stat[6,4],2),"%",
           "(SD ",round(King_stat[6,5],3), ")", " for ", King_stat[6,1], " at year ",
       King_stat[6,2], sep = "")

paste( "The reads of ", King_stat[10,3], " is ",round(King_stat[10,4],2),"%",
           "(SD ",round(King_stat[10,5],3), ")", " for ", King_stat[10,1],  " at year ",
       King_stat[10,2],sep = "")

King_stat1 <- Kingdoms %>%
  filter(Sample_or_Control == "Sample") %>%
  mutate(status = ifelse(Year_since_decay_start %in% c(0), "non_decayed", "decayed")) %>%
  group_by(Tree_host, status, Kingdom) %>%
  dplyr::summarise(mean=mean(Abundance)*100, sd=sd(Abundance)) %>%
  arrange(dplyr::desc(mean)) %>%
  as.data.frame()
write.csv(King_stat1, "results/kingdom_stats_1.csv")
```

```{r}
# Statistical summary of ASV classified as non phylum after removing non-fungal sequence (Phylum = NA )
length(get_taxa_unique(ps.fungi,taxonomic.rank="Phylum")) #13
 
Phylums <- ps.fungi %>%
  aggregate_taxa("Phylum") %>% 
  transform_sample_counts(function(x) {x/sum(x)}) %>% 
  psmelt() %>%
  arrange(Phylum)
Phy_stat <- Phylums %>%
  dplyr::group_by(Tree_host,  Year_since_decay_start,  Phylum) %>%
  dplyr::reframe(mean=mean(Abundance, na.rm = T)*100, sd=sd(Abundance, na.rm = T)) %>%
  arrange(dplyr::desc(mean)) %>%
  as.data.frame()
write.csv(Phy_stat, "results/phylum_stats.csv")
```

## Identifying and remove contaminants in marker-gene data
Here is a link <https://benjjneb.github.io/decontam/vignettes/decontam_intro.html> to decotam instruction.
```{r}
# Inspect Library Sizes
depth_df <- depth_track1[order(depth_track1$nonfungal_filtered),]
depth_df$Index <- seq(nrow(depth_df))
ggplot(data=depth_df, aes(x=Index, y=nonfungal_filtered, color=Sample_or_Control)) + 
  geom_point()

# Identify Contaminants - Prevalence
sample_data(ps.fungi)$is.neg <- sample_data(ps.fungi)$Sample_or_Control == "Control"
contamdf.prev <- isContaminant(ps.fungi, method="prevalence", neg="is.neg")
head(contamdf.prev)

table(contamdf.prev$contaminant)

head(which(contamdf.prev$contaminant))

# More aggressive classification threshold 
contamdf.prev05 <- isContaminant(ps.fungi, method="prevalence", neg="is.neg", threshold=0.5)
table(contamdf.prev05$contaminant)
head(which(contamdf.prev05$contaminant))

# Remove contaminants
ps.noncontam <- prune_taxa(!contamdf.prev$contaminant, ps.fungi)

# Remove negative control
ps.noncontam <- subset_samples(ps.noncontam, ! sample_names(ps.noncontam) %in% c("C0", "Q0"))
ps.noncontam <- prune_taxa(taxa_sums(ps.noncontam)>0, ps.noncontam)

saveRDS(ps.noncontam, "results/ps.noncontam.rds")

# Make a data frame with a column for the read counts of each sample
depth_track2 <- data.frame(sample_data(ps.noncontam)) %>%
  mutate(decontam = sample_sums(ps.noncontam)) %>%
  right_join(depth_track1)


# Statistic of reads after removing contaminants
depth_track2 %>%
  group_by(Tree_host, Protocol, Year_since_decay_start) %>%
  dplyr::summarise(mean(decontam), sd(decontam))
```

## Quality control 
I will remove microbes that do not show up regularly. These are noisy OTUs, and while they may be real, they most likely popped up through contamination, sequencing and PCR error. They make the downstream stats noisy, and so I will remove them. In this dataset, I will remove OTUs that represented by less than ten reads in a given sample.
```{r}
# 1. Total-frequency-based filtering
# 1.1 Sample Filtering--Remove samples with low- or poor-quality sequence data (samples with less than 1000 fungal reads).
ps1 <- subset_samples(ps.noncontam, sample_sums(ps.noncontam)>=200) # 2 samples removed
ps1 = prune_taxa(taxa_sums(ps1)>0, ps1)

# 1.2 Taxa Filtering--Remove instances of ASVs represented by less than  2 reads.
#ps2 <- subset_samples(ps1, taxa_sums(ps1)>=2)

# 2. Prevalence based filtering 
# 2.1 Remove instances of ASVs represented by less than  10 reads in a given sample.
ps2 = filter_taxa(ps1, function(x) sum(x >= 10) >= 1, TRUE)

# 2.2 Remove instances of ASVs showed up in less than 2% samples
#ps3 = filter_taxa(ps2, function(x) sum(x > 0) >= (0.02*length(x)), TRUE)

# How many phylum would be present after filtering? #12
length(get_taxa_unique(ps2,taxonomic.rank="Phylum"))
# Create table, number of features for each phyla
table(tax_table(ps2)[,"Phylum"],exclude=NULL)

cat(ntaxa(ps.its), "OTUs in original table.\n")
cat(ntaxa(ps.fungi), "OTUs in taxnomic filtered table.\n")
cat(ntaxa(ps.noncontam), "OTUs in  contanimation filtered table.\n")
cat(ntaxa(ps2), "OTUs in quality controlled table.\n")

saveRDS(ps1, "results/ps1.rds")
saveRDS(ps2, "results/ps2.rds")

# How many "reads" does each filtration leave us at??
c(sum(colSums(otu_table(ps.its))), sum(colSums(otu_table(ps.fungi))), 
  sum(colSums(otu_table(ps.noncontam))), sum(colSums(otu_table(ps1))),
  sum(colSums(otu_table(ps2))))

ps.nondecayed <- subset_samples(ps2, Year_since_decay_start == "0")
ps.nondecayed  = prune_taxa(taxa_sums(ps.nondecayed )>0, ps.nondecayed )
cat(ntaxa(ps.nondecayed), "OTUs in non-decayed wood.\n")

ps.decayed <- subset_samples(ps2, !Year_since_decay_start == "0")
ps.decayed  = prune_taxa(taxa_sums(ps.decayed )>0, ps.decayed )
cat(ntaxa(ps.decayed), "OTUs in decayed wood.\n")

# Make a data frame with a column for the read counts of each sample
depth_track3 <- data.frame(sample_data(ps2)) %>%
  mutate(quality_filtered = sample_sums(ps2)) %>%
  right_join(depth_track2)

# Statistic of reads after quality control
depth_track3 %>%
  group_by(Tree_host, Protocol, Year_since_decay_start) %>%
  #dplyr::summarise(mean(quality_filtered, na.rm = T), sd(quality_filtered, na.rm = T))
  get_summary_stats(quality_filtered, type = "mean_sd")
```

### Repeated ANOVA or Friedman test (more than 2 groups)
The goal is to assess the effect of extraction methodology on the read depth. For this analysis, treatments were considered to be those samples from the same tree hosts, logs, and sampling times. The samples from the same treatments were paired across the extraction methodologies. Therefore, extraction methodology was the single independent variable and we measured the read depth in response to this variable. 
```{r}
# Summary statistics
depth_track3 %>% 
  filter(Sample_or_Control == "Sample") %>%
  group_by(Protocol) %>%
  get_summary_stats(quality_filtered, type = "mean_sd")

# Check assumptions
## Outliers
depth_track3 %>%
  group_by(Protocol) %>%
  identify_outliers(quality_filtered)
# no outliers were found
## Normality
depth_track3 %>%
  group_by(Protocol) %>%
  shapiro_test(quality_filtered)
# CTAB group are not normally distributed
ggqqplot(depth_track3, "quality_filtered", facet.by = "Protocol")
# Or build the linear model
model  <- lm(quality_filtered ~ Protocol, data = depth_track3)
# Create a QQ plot of residuals
ggqqplot(residuals(model))
# Compute Shapiro-Wilk test of normality
shapiro_test(residuals(model))
# The data is not normally distributed

# Friedman test 
res.fried <- depth_track3 %>% 
  #filter(Sample_or_Control == "Sample") %>%
  filter (SampleID != c("Q27", "Q04")) %>% # Remove Q27, Q04 to fo the repeated measure as the C27, C04 is filterd out before
  rstatix::friedman_test(quality_filtered ~ Protocol |Sample_name)
res.fried 

# Birch
depth_track3 %>% 
  #filter(Sample_or_Control == "Sample") %>%
  filter (SampleID != c("Q27", "Q04")) %>% # Remove Q27 to fo the repeated measure as the C27 is filterd out before
  filter(Tree_host == "paper_birch") %>% 
  rstatix::friedman_test(quality_filtered ~ Protocol |Sample_name)
# Pine
depth_track3 %>% 
  #filter(Sample_or_Control == "Sample") %>%
  filter(Tree_host == "red_pine") %>% 
  rstatix::friedman_test(quality_filtered ~ Protocol |Sample_name)
```

### Paired t test to test the effect of protocol on reading depth adter filtration
```{r}
depth_track3.wide <- depth_track3 %>% 
  filter(Sample_or_Control == "Sample") %>%
  select(Tree_log, Tree_host, Year_since_decay_start,Protocol, quality_filtered) %>% 
  spread(key = "Protocol", value = "quality_filtered")  %>% 
  mutate(differences = QIAGEN - CTAB)

# Check assumptions
depth_track3.wide %>% 
  identify_outliers(differences)
# No outliers
depth_track3.wide %>% 
  shapiro_test(differences) 
# Normally distributed
depth_track3.wide %>% 
  ggqqplot("differences")

stat.test <- depth_track3 %>%
  filter(Sample_or_Control == "Sample") %>%
  rstatix::t_test(quality_filtered ~ Protocol, p.adjust.method = "bonferroni", paired=T) %>%
  add_significance() 
stat.test

# Effect size
depth_track3  %>% 
  filter(Sample_or_Control == "Sample") %>%
  cohens_d(quality_filtered ~ Protocol, paired = TRUE)

stat.test <- stat.test %>% add_xy_position(x = "Protocol")

p <- ggplot(depth_track3 %>% filter(Sample_or_Control == "Sample"),  
            aes(x = Protocol, y = quality_filtered, color = Protocol))+
  geom_boxplot(aes(fill = Protocol), alpha = 0.3)+
  geom_jitter(position = position_jitterdodge(),size =1, alpha = 0.3) +
  scale_color_manual(values =  c("#F8766D", "#00BA38")) +
  scale_fill_manual(values =  c("#F8766D", "#00BA38")) +
  labs(x = "Year_since_decay_start", y = "Total reads")+
  theme(axis.text.x=element_text(vjust=1, hjust=1)) +
  theme_bw(7) +
  theme(legend.key.size = unit(0.2, "cm"),
                    legend.title = element_blank()) +
  stat_pvalue_manual(stat.test, tip.length = 0, hide.ns = TRUE)
  #stat_compare_means(aes(group = Protocol), label = "p.signif", method = "t.test", paired = T, size=1.5)
p

ggsave("results/pictures/newdatabase/reads_vs_protocol.pdf", p)

# Remove the pair with one NA
depth_track3 %>%
    filter(Sample_or_Control == "Sample") %>% filter (!SampleID %in% c("Q27", "C27", "Q04", "C04")) %>% 
    rstatix::t_test(quality_filtered ~ Protocol, p.adjust.method = "bonferroni", paired=T) %>%
    add_significance() 
```

paired t test or Wilcoxon test on each group
```{r}
depth_track3.wide %>% 
  group_by(Tree_host, Year_since_decay_start) %>% 
  identify_outliers(differences)
# Outliers were found
depth_track3.wide %>% 
  group_by(Tree_host, Year_since_decay_start) %>% 
  shapiro_test(differences) 
# One group not normally distributed
depth_track3.wide %>% 
  ggqqplot("differences", facet.by = c("Tree_host", "Year_since_decay_start"))

# The data have outliers and don't have a normal distribution. The non-parametric tests, such as Wilcoxon test, are recommended.
gghistogram(depth_track3.wide, x = "differences", y = "..density..", 
            fill = "steelblue",bins = 5, add_density = TRUE)
#  it can be seen that the differences data are approximately symmetrical (you should not expect them to be perfect, particularly when you have smaller numbers of samples in your study). Therefore, we can use the Wilcoxon signed-rank test to analyse our data.

# paired wilcox test of protocol effect  
stat.test <- depth_track3 %>%
  filter(Sample_or_Control == "Sample") %>%
  group_by(Tree_host, Year_since_decay_start) %>%
  rstatix::wilcox_test(quality_filtered ~ Protocol, p.adjust.method = "bonferroni",
                       paired=T) %>%
  add_significance() 
stat.test  

# Effect size
depth_track3  %>%
  filter(Sample_or_Control == "Sample") %>%
  group_by(Tree_host, Year_since_decay_start) %>%
  wilcox_effsize(quality_filtered ~ Protocol, paired = TRUE)

stat.test <- stat.test %>% add_xy_position(x = "Year_since_decay_start")

p <- ggplot(depth_track3 %>% filter(Sample_or_Control == "Sample"),  
            aes(x = as.factor(as.character(Year_since_decay_start)), y = quality_filtered, color = Protocol))+
  geom_boxplot(aes(fill = Protocol), alpha = 0.3)+
  geom_jitter(position = position_jitterdodge(),size =1, alpha = 0.3) +
  #scale_y_log10()+
  facet_grid(Tree_host~.)+
  scale_color_manual(values =  c("#F8766D", "#00BA38")) +
  scale_fill_manual(values =  c("#F8766D", "#00BA38")) +
  labs(x = "Year_since_decay_start", y = "Total reads")+
  theme(axis.text.x=element_text(vjust=1, hjust=1)) +
  theme_bw(7) +
  theme(legend.key.size = unit(0.2, "cm"),
                    legend.title = element_blank()) +
  stat_pvalue_manual(stat.test, tip.length = 0, hide.ns = TRUE)
  #stat_compare_means(aes(group = Protocol), label = "p.signif", method = "wilcox.test", paired = T, size=1.5)
p

ggsave("results/pictures/newdatabase/reads_vs_protocol_group_by.pdf", p)

# Remove the pair with one NA
depth_track3 %>%
  filter(Sample_or_Control == "Sample") %>% filter (!SampleID %in% c("Q27", "C27", "C04", "Q04")) %>% 
  group_by(Tree_host, Year_since_decay_start) %>%
  rstatix::wilcox_test(quality_filtered ~ Protocol, p.adjust.method = "bonferroni", paired=T) %>%
  add_significance() 
```



### t test to test the effect of DECAY STATUS on reading depth adter filtration
The goal is to assess the effect of decay status on the read depth. The samples are not paired
```{r}
# Decay status effect
depth_track4 <- depth_track3 %>%
  filter(Sample_or_Control == "Sample") %>%
  mutate(status = ifelse(Year_since_decay_start %in% c(0), "non_decayed", "decayed")) 

depth_track4$status <- factor(depth_track4$status, level = c("non_decayed", "decayed"))
depth_track4 %>%
  # remove decayed samples in time 0 (pine log 06, pine log 07)
  #subset(! row.names(df_nonhost) %in% c("C36","Q36", "C37", "Q37")) %>% 
  group_by(status) %>%
  #dplyr::summarise(range(quality_filtered), mean(quality_filtered), sd(quality_filtered))
  get_summary_stats(quality_filtered, show = c("mean","sd", "min", "max"))

# Check assumptions
## Outliers
depth_track4 %>%
  group_by(status) %>%
  identify_outliers(quality_filtered)
# no outliers were found
## Normality
depth_track4 %>%
  group_by(status) %>%
  shapiro_test(quality_filtered)
# Non-decayed group not normally distributed
ggqqplot(depth_track4, "quality_filtered", facet.by = "status")
# Or build the linear model
model  <- lm(quality_filtered ~ status, data = depth_track4)
# Create a QQ plot of residuals
ggqqplot(residuals(model))
# Compute Shapiro-Wilk test of normality
shapiro_test(residuals(model))
# The data is not normally distributed

# Homogneity test
#depth_track4 %>% levene_test(quality_filtered ~ status)
# The p-value of the Levene’s test is not significant, suggesting that there is no significant difference between the variances of the two # groups. Therefore, we’ll use the classic t-test, which assume the equality of the two variances.

# if the data are not normally distributed, it’s recommended to use the non parametric two-samples Wilcoxon rank test.

# Computation

stat.test <- depth_track4 %>% 
  wilcox_test(quality_filtered ~ status) %>%
  add_significance()
stat.test

#Effect size
#depth_track4 %>%  cohens_d(quality_filtered ~ status, var.equal = F)
depth_track4 %>% wilcox_effsize(quality_filtered ~ status)

stat.test <- stat.test %>% add_xy_position(x = "status")

p <- ggplot(depth_track4, aes(x=status, y=quality_filtered, color=status))+
  geom_boxplot(aes(fill = status), alpha = 0.3)+
  geom_jitter(position = position_jitterdodge(),size =1, alpha = 0.3) +
  #scale_y_log10()+
  #facet_grid(Tree_host~.)+
  scale_color_manual(values=c("lightgrey", "#5C4033")) +
  scale_fill_manual(values=c("lightgrey", "#5C4033")) +
  labs(x = "Decay Status", y = "Quality Filtered Reads")+
  theme_bw(7) +
  theme(legend.key.size = unit(0.2, "cm"),
                    legend.title = element_blank()) +
  stat_pvalue_manual(stat.test, tip.length = 0, hide.ns = TRUE)


p

ggsave("results/pictures/newdatabase/reads_vs_status.pdf", p, width = 3, height = 2.5)

depth_track4 %>%
  # remove decayed samples in time 0 (pine log 06, pine log 07)
  #subset(! row.names(df_nonhost) %in% c("C36","Q36", "C37", "Q37")) %>% 
  group_by(Tree_host, status) %>%
  get_summary_stats(quality_filtered, show = c("mean","sd", "min", "max"))

# Birch
depth_track4 %>% 
  filter(Tree_host == "paper_birch") %>% 
  wilcox_test(quality_filtered ~ status) %>%
  add_significance()
# Pine
depth_track4 %>% 
  filter(Tree_host == "red_pine") %>% 
  wilcox_test(quality_filtered ~ status) %>%
  add_significance()
```

## Data stat after filtration and quality control
```{r}
# Define prevalence of each taxa (in how many samples did each taxa appear at least ten times)
prev10 = apply(X = otu_table(ps1),
               MARGIN = ifelse(taxa_are_rows(ps1), yes = 1, no = 2),
               FUN = function(x){sum(x >= 10)})
# Add taxonomy and total read counts to this data.frame
prevdf = data.frame(Prevalence = prev10,
                    TotalAbundance = taxa_sums(ps1),
                    tax_table(ps1))

clean_stats <- prevdf %>% 
  dplyr::mutate(status = ifelse(Prevalence >= 1, "keep", "discard"))
# Store discard taxa after quality control
taxa_discarded <-  clean_stats%>% 
  filter(status == "discard") %>% 
  arrange(-TotalAbundance)

write.csv(taxa_discarded, "results/qc_discared_taxa.csv")

p <- ggplot(clean_stats, aes(x = TotalAbundance, y = Prevalence, color = status)) +
  geom_point(alpha = 0.05) +
  #scale_y_log10() +
  scale_x_log10() +
  scale_color_manual(values = c("red", "black")) +
  theme_bw(7) +
  theme(legend.key.size = unit(0.2, "cm"),
                    legend.title = element_blank()) +
  labs(x = "Total Abundance", y = "Prevalence (>=10)")
p

ggsave("results/pictures/newdatabase/Prevalence_10_versus_total_abundance.pdf", p, width = 3, height = 2.5)

```

## Track sample reads depth
Let's see the treacking summary of sequencing depth during reads processing
```{r}
# Loading reads track file
dada_track = read.delim("../03_tabletax/dada2_its2_track.txt")

dada_track <-  dada_track %>% mutate(SampleID = row.names(.))
  
depth_track5 <- merge(dada_track, 
                      depth_track4[, c("SampleID", "Tree_log", "Tree_host", "Protocol", "Year_since_decay_start", "DNA_yields", 
                                        "nonfungal_filtered", "decontam", "quality_filtered")],
              by = "SampleID", all = F)


track_l<- reshape2::melt(depth_track5, id.vars=c("SampleID", "Tree_log", "Tree_host", "Protocol", "Year_since_decay_start",
                                                 "DNA_yields"),
                         variable.name = "step", value.name = "reads_count")

track_l$Protocol<-factor(track_l$Protocol, level = c("QIAGEN", "CTAB"))
head(track_l)

p <-  ggplot(track_l,aes(x = step, y = reads_count, color = Protocol)) +
  geom_line(aes(group = SampleID, color = Protocol)) +
  geom_point(aes(color= Protocol), pch = 21,size = 1) +
  facet_grid(Year_since_decay_start~Tree_host) +
  scale_color_manual(values =  c("#F8766D", "#00BA38")) +
  scale_fill_manual(values =  c("#F8766D", "#00BA38")) 

p <-  p +
  theme_bw(7)+
  theme(legend.key.size = unit(0.2, "cm"),
                    legend.title = element_blank()) +
  theme(axis.title.x = element_blank())

if (length(unique(track_l$SampleID))>3){  
  p=p+theme(axis.text.x=element_text(angle=45,vjust=1, hjust=1))
}

p
ggsave("results/pictures/newdatabase/track_for_all_count.pdf", p, width = 5, height = 2.5)
```

```{r}
# Statistic of reads after merge in dada2
depth_track5 %>%
  group_by(Tree_host, Year_since_decay_start) %>%
  dplyr::summarise(mean(merged/denoisedF), sd(merged/denoisedF))
depth_track5 %>%
  group_by(Tree_host, Year_since_decay_start) %>%
  dplyr::summarise(mean(merged/input), sd(merged/input))

depth_track5 %>%
  group_by(Tree_host, Year_since_decay_start) %>%
  dplyr::summarise(mean(nonchim), sd(nonchim))

depth_track5 %>%
  group_by(Tree_host, Year_since_decay_start, Protocol) %>%
  dplyr::summarise(mean(nonchim), sd(nonchim))

depth_track5 %>%
  mutate(status = ifelse(Year_since_decay_start %in% c(0), "non_decayed", "decayed")) %>%
  group_by(Tree_host, status) %>%
  dplyr::summarise(mean(nonchim), sd(nonchim))

depth_track5 %>%
  mutate(status = ifelse(Year_since_decay_start %in% c(0), "non_decayed", "decayed")) %>%
  group_by(Tree_host, status) %>%
  dplyr::summarise(mean(merged), sd(merged))

depth_track5 %>%
  group_by(Tree_host, Year_since_decay_start) %>%
  dplyr::summarise(mean(nonfungal_filtered/nonchim), sd(nonfungal_filtered/nonchim))

```

## Report of sequencing data after non fungal taxa and contaminants removal
```{r}
# Step_1:
where <- "dead wood"
method <- "using ITS2 rRNA gene amplicon sequencing."
rep = 8
step_1 <- paste("We analyzed the composition of fungal communities in the",where,method)
step_1

# Step_2: Statistical summary of reads in each sample
repead <- paste("For this analysis, we collected",rep,"repeats for each samples.")
repead

each_count <- paste(repead, "We obtained an average read count per sample of",
                    round(mean(sample_sums(ps2)),0), "with a ange between",
                    round(min(sample_sums(ps2)),0), "and",
                    round(max(sample_sums(ps2)),0),
                    "(standard deviation(SD)", round(sd(sample_sums(ps2)),2),").")
each_count

# Step_3: Statistical summary of ASV in each sample (richness)
otu_table = otu_table(ps2) %>% as.matrix

# Observed taxa -  how many taxa in each samples
otu_table [otu_table > 0] <-1
OTU_sum <- colSums(otu_table)  

sample_tax <- paste("The numbers of OTU, generally ranged between",
                    min(OTU_sum),"and",max(OTU_sum),"per sample with an average of",
                    round(mean(OTU_sum),0),"(SD ",round(sd(OTU_sum)),").")
sample_tax

OTU_sum <- OTU_sum %>% data.frame() 
colnames(OTU_sum) <- "ASV_number"
OTU_sum$SampleID <- row.names(OTU_sum)

depth_tax <- full_join(depth_track5, OTU_sum, by= "SampleID")


depth_tax <- depth_tax[, c(1, 8:12, 2:7, 13:16)] 

write.csv(depth_tax, "results/sample_reading_depth_track_ntaxa.csv")

# Step 4: Statistical summary of ASV per sample at the level of phylum
Taxonomies <- ps2 %>%
  #tax_glom(taxrank = "Phylum") %>% 
  tax_glom_wt(ranks = "Phylum") %>%
  transform_sample_counts(function(x) {x/sum(x)} )%>% 
  psmelt() %>%
  #filter(Abundance > 0.05) %>%
  arrange(Phylum)

taxa_groups<- group_by(Taxonomies, Phylum)
taxa_sum <- dplyr::summarise(taxa_groups, mean(Abundance), sd(Abundance))
taxa_sum[is.na(taxa_sum)] <- 0

colnames(taxa_sum) = c("ID","mean","sd")
taxa_sum <- dplyr::arrange(taxa_sum,desc(mean))
taxa_sum$mean <- taxa_sum$mean *100
taxa_sum <- as.data.frame(taxa_sum)
head(taxa_sum)

a = paste(taxa_sum[1,1],"(",round(taxa_sum[1,2],2),"%"," with sd ",round(taxa_sum[1,3],3),"),",sep = "")
b = paste(taxa_sum[2,1],"(",round(taxa_sum[2,2],2),"%"," with sd ",round(taxa_sum[2,3],3),"),",sep = "")
c = paste(taxa_sum[3,1],"(",round(taxa_sum[3,2],2),"%"," with sd ",round(taxa_sum[3,3],3),"),",sep = "")
d = paste(taxa_sum[4,1],"(",round(taxa_sum[4,2],2),"%"," with sd ",round(taxa_sum[4,3],3),"),",sep = "")
e = paste(taxa_sum[5,1],"(",round(taxa_sum[5,2],2),"%"," with sd ",round(taxa_sum[5,3],3),").",sep = "")

tax_sum = paste("The majority of OTU belonged to the phyla",a,b,c,d,"and",e)
tax_sum

##all_first 
line = paste(step_1,each_count,sample_tax,tax_sum)
line

write.table(line,"results/microbiome_first_line.txt",quote = F)
```